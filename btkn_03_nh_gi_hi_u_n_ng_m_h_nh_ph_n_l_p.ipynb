{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mn987/manager_student2/blob/master/btkn_03_nh_gi_hi_u_n_ng_m_h_nh_ph_n_l_p.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OStmxt0neFNx",
        "outputId": "575ad1df-5940-4651-90a4-af12b1d7139e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\an\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqpv4ewOeFNz"
      },
      "outputs": [],
      "source": [
        "def readData(filePath: str, filename: str):\n",
        "    data = np.loadtxt(os.path.join(filePath, filename), delimiter = ',')\n",
        "    X = data[:,:-1]\n",
        "    y = data[:, -1]\n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "    X = np.reshape(X, (m,n))\n",
        "    y = np.reshape(y, (m,1))\n",
        "    #Them cot x0 = 1 vao X\n",
        "    x0 = np.ones((m,1))\n",
        "    X = np.column_stack([x0, X])\n",
        "    return X, y\n",
        "\n",
        "def featureVectorScaling(data):\n",
        "    avg = np.mean(data)\n",
        "    sln = data.max()\n",
        "    snn = data.min()\n",
        "    data_scl = (data - avg)/(sln - snn)\n",
        "    print(data_scl[1])\n",
        "    return data_scl\n",
        "\n",
        "def normalizeData(X):\n",
        "    X_scl = X[:, 0]\n",
        "    for i in range(1, X.shape[1]):\n",
        "        scl = featureVectorScaling(X[:, i])\n",
        "        X_scl = np.column_stack([X_scl, scl])\n",
        "    return X_scl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ofklQ3NeFN0"
      },
      "outputs": [],
      "source": [
        "def MeanNormalization(data):\n",
        "    avg = np.mean(data)\n",
        "    sln = data.max()\n",
        "    snn = data.min()\n",
        "    data_scl = (data - avg)/(sln - snn)\n",
        "    return data_scl\n",
        "\n",
        "def scaleData_MeanNormalization(X):\n",
        "    X_scl = X[:, 0]\n",
        "#     Pdb().set_trace()\n",
        "    for i in range(1,X.shape[1]):\n",
        "        scl = MeanNormalization(X[:,i])\n",
        "        X_scl = np.column_stack([X_scl,scl])\n",
        "    return X_scl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd9B0_Z-eFN1"
      },
      "outputs": [],
      "source": [
        "#Day chinh la ham  hw(X)\n",
        "def sigmoid(X, w):\n",
        "    result = 1/(1 + np.exp(-np.dot(X, w)))\n",
        "    return result\n",
        "\n",
        "def loss(X, y, w):\n",
        "    m = y.shape[0]\n",
        "    result = (-1/m)*np.sum(np.dot(y.T, np.log(sigmoid(X, w)))) + np.dot((1 - y).T, np.log(1 - sigmoid(X, w)))\n",
        "    return result\n",
        "\n",
        "def gradient(X, y, w):\n",
        "    m = X.shape[0]\n",
        "    result = (1/m)*np.dot(X.T, sigmoid(X, w) - y)\n",
        "    return result\n",
        "\n",
        "def gradientDescent(X, y, w, alpha, n_iters):\n",
        "    w_optimal = w.copy()\n",
        "    J_history = []\n",
        "    for i in range(n_iters):\n",
        "        w_optimal = w_optimal - alpha*gradient(X, y, w_optimal)\n",
        "        J_history.append(loss(X, y, w_optimal))\n",
        "    return w_optimal, J_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNFi928ZeFN1"
      },
      "outputs": [],
      "source": [
        "#Hàm dự đoán nếu y_pred >=0.5 làm tròn thành 1, ngược lại là 0\n",
        "def predict(y_pred):\n",
        "    return np.rint(y_pred)\n",
        "\n",
        "def acc_score(y, y_hat):\n",
        "    m = y.shape[0]\n",
        "    result = (1/m)*np.sum(y == y_hat)\n",
        "    return  result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj8zm7dxeFN2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "def top_k_acc_score(y, y_hat):\n",
        "    n = y.shape[0]\n",
        "    result = 1/n*(np.sum(sorted(y_hat)==y))\n",
        "    return result\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "#balanced-accuracy = 1/2( TP/(TP+FN) + TN/(TN+FP) ) \n",
        "# TP: số lần số 1 xuất hiện TRUE\n",
        "# TN: số lần số 0 xuất hiện TRUE\n",
        "# FP: số lần số 1 xuất hiện FALSE\n",
        "# FN: số lần số 0 xuất hiện FALSE    \n",
        "\n",
        "def balanced_acc_score(y, y_hat):\n",
        "    \n",
        "    #tạo danh sách temp so sánh các biến của hai cột y, y_hat và trả về 2 giá trị TRUE, FALSE\n",
        "    temp = []\n",
        "    temp_matrix = np.column_stack([y,y_hat])\n",
        "#     pdb.set_trace()\n",
        "    print(temp_matrix)\n",
        "    for i in range(len(y)):\n",
        "        if temp_matrix[i,0] == temp_matrix[i,1]:\n",
        "            if temp_matrix[i,0] == 1:\n",
        "                temp.append('1TRUE')\n",
        "            else:\n",
        "                temp.append('0TRUE')\n",
        "    print(temp)\n",
        "    print(len(temp),len(temp_matrix[:,0]))\n",
        "    temp_matrix = np.column_stack([temp_matrix,temp])\n",
        "    print(temp_matrix)\n",
        "#     temp = temp_matrix[:,2].tolist()\n",
        "#     TP = temp.count('TRUE')\n",
        "#     TN = temp.count('FALSE')\n",
        "#     FP = TN\n",
        "#     FN = TP\n",
        "#     result = 1/2*(TP/(TP+FN) + TN/(TN+FP))\n",
        "#     return result\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "def recall_Score():\n",
        "    pass\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPAXVwMfeFN2"
      },
      "outputs": [],
      "source": [
        "folder = 'C:/Users/MSI/Downloads/Machine Learning1/Data'\n",
        "filename = 'ex2data1.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PnQr9KyeFN3",
        "outputId": "f771d6a9-6034-477d-c3fb-396553b30c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.5067801656080071\n",
            "-0.3270580397857178\n",
            "Ket qua huan luyen mo hinh la: \n",
            "\t\tTrong so w toi uu la:  [[0.11388737]\n",
            " [1.42359466]\n",
            " [1.09000762]]\n",
            "\t\tGia tri Loss toi uu:  [[-18.24719421]]\n",
            "Ket qua du doan cua mo hinh\n",
            "\t\tMột số kết quả dự đoán:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "\t\tChỉ số Accuracy:  0.8333333333333334\n",
            "\t\tSử dụng sklearn, Acc:  0.8333333333333334\n",
            "\t\tChỉ số Top-k Accuracy score:  0.6333333333333333\n",
            "\t\tSử dụng sklearn, Top-k Acc score:  1.0\n",
            "\t\tSử dụng sklearn, Balanced Acc score:  0.8333333333333334\n",
            "\t\tSử dụng sklearn, Recall score:  0.8333333333333334\n",
            "\t\tSử dụng sklearn, F1 score:  0.8444444444444446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\an\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1748: UndefinedMetricWarning: 'k' (2) greater than or equal to 'n_classes' (2) will result in a perfect score and is therefore meaningless.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    X, y = readData(folder, filename)\n",
        "    X = normalizeData(X)\n",
        "    n = X.shape[1]\n",
        "    w = np.zeros((n, 1))\n",
        "    alpha = 0.01\n",
        "    n_iters = 2000\n",
        "    #Chia train - test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.30,\n",
        "                                                        random_state=15, shuffle=False)\n",
        "    w_opt, J_hist = gradientDescent(X_train, y_train, w, alpha, n_iters)\n",
        "    print(\"Ket qua huan luyen mo hinh la: \")\n",
        "    print('\\t\\tTrong so w toi uu la: ', w_opt)\n",
        "    print('\\t\\tGia tri Loss toi uu: ', J_hist[-1])\n",
        "    print('Ket qua du doan cua mo hinh')\n",
        "    y_hat = predict(sigmoid(X_test, w_opt))\n",
        "    print('\\t\\tMột số kết quả dự đoán: ', y_hat[:5,:])\n",
        "    print('\\t\\tChỉ số Accuracy: ', acc_score(y_test, y_hat))\n",
        "    print('\\t\\tSử dụng sklearn, Acc: ', accuracy_score(y_test.flatten(), y_hat.flatten()))\n",
        "    \n",
        "    print('\\t\\tChỉ số Top-k Accuracy score: ', top_k_acc_score(y_test, y_hat))\n",
        "    print('\\t\\tSử dụng sklearn, Top-k Acc score: ', top_k_accuracy_score(y_test.flatten(), y_hat.flatten()))\n",
        "#     print('\\t\\tChỉ số Balanced Accuracy score: ', balanced_acc_score(y_test, y_hat))\n",
        "    print('\\t\\tSử dụng sklearn, Balanced Acc score: ', balanced_accuracy_score(y_test.flatten(), y_hat.flatten()))\n",
        "    print('\\t\\tSử dụng sklearn, Recall score: ', recall_score(y_test.flatten(), y_hat.flatten(), average='weighted'))\n",
        "    print('\\t\\tSử dụng sklearn, F1 score: ', f1_score(y_test.flatten(), y_hat.flatten(), average='weighted'))\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}